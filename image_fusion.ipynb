{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, os.path\n",
    "import scipy.ndimage\n",
    "from PIL import Image\n",
    "\n",
    "# Function for basis_details_decomposition (Corresponds to equation 10 and 11 from the article)\n",
    "def basis_details_decomposition(images_tuple, avg_size=31):\n",
    "    kernel = np.ones((avg_size, avg_size), np.float32) / avg_size ** 2\n",
    "    basis_list = []\n",
    "    details_list = []\n",
    "    for im in images_tuple: \n",
    "        #basis=scipy.ndimage.correlate(im, kernel, mode='nearest')\n",
    "        basis=np.array(cv2.blur(im, (avg_size,avg_size),borderType=cv2.BORDER_REPLICATE), np.float64)\n",
    "        #basis=np.array(cv2.boxFilter(im,-1,(avg_size,avg_size) ), np.float64)\n",
    "        details=np.array(im, np.float64) - basis\n",
    "        basis_list.append(basis)\n",
    "        details_list.append(im - basis)\n",
    "    return tuple(basis_list), tuple(details_list)\n",
    "\n",
    "\n",
    "# Function for saliencies (laplacian filter + gaussian lowpass filter)\n",
    "# Corresponds to equation 13 in the article\n",
    "def saliency_maps(images_tuple, lapsize, rg, sigmag):\n",
    "    saliency_list = []\n",
    "    for im in images_tuple:\n",
    "        laplacian = abs(cv2.Laplacian(im, cv2.CV_64F))\n",
    "        saliency = cv2.GaussianBlur(laplacian, (2 * rg + 1, 2 * rg + 1), sigmag)\n",
    "        saliency_list.append(saliency)\n",
    "        s=np.array(saliency_list)+1e-12\n",
    "        saliency_list_normalized=list((s/np.sum(s,axis=0)))\n",
    "    return tuple( saliency_list_normalized)\n",
    "\n",
    "\n",
    "# Weight map function (corresponds to equation (14) from the arcticle)\n",
    "def weight_map_construction(saliency_tuple):\n",
    "    # Intialize weight maps to zero\n",
    "    dims = saliency_tuple[0].shape\n",
    "    nims = len(saliency_tuple)\n",
    "    \n",
    "    weight_maps = [np.zeros(dims, np.uint8) for i in range(0, nims)]\n",
    "    # Loop over color channels (we have one weight map per channel)\n",
    "    argmax=np.argmax(saliency_tuple,axis=0)\n",
    "    # Use that information to fill the weight maps\n",
    "    for i in range(0, nims):\n",
    "        # Get the indicator for each pixel and fill the corresponding arrays\n",
    "        weight_maps[i]= (argmax == i).astype(np.uint8)\n",
    "    return weight_maps\n",
    "\n",
    "# Produce refined weights maps using guided filtering (Function for equations 15 and 16 of the article)\n",
    "def refined_weight_maps(guides_tuple, images_tuple, r, eps):\n",
    "    nims = len(images_tuple)\n",
    "    outputs = []\n",
    "    for i in range(0, nims):\n",
    "        gf = cv2.ximgproc.createGuidedFilter(images_tuple[i], r, eps)\n",
    "        filtered= gf.filter(guides_tuple[i])\n",
    "        \n",
    "        \n",
    "        outputs.append(filtered)\n",
    "    return tuple(outputs)\n",
    "\n",
    "\n",
    "# Pixel by pixel normalization\n",
    "def weight_maps_normalization(weights_tuple):\n",
    "    \n",
    "    weights_list=np.array(list(weights_tuple))\n",
    "    weights_list=cv2.convertScaleAbs( weights_list*255)\n",
    "    weights_list=weights_list.astype(float)/255\n",
    "    weights_list= weights_list+1e-12\n",
    "    \n",
    "    weights_list_normalized=list(weights_list/np.sum(weights_list,axis=0))\n",
    "    return tuple(weights_list_normalized)\n",
    "\n",
    "\n",
    "def images_weighted_average(weights_tuple, images_tuple):\n",
    "    #size=np.array(weights_tuple).shape+(1,)\n",
    "    return np.sum(np.array(weights_tuple) * np.array(images_tuple), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Loadings and other prerequisites #############################################################\n",
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f\n",
    "# Path to the data\n",
    "imgs = []\n",
    "path = os.getcwd() + \"/Data/rose\"\n",
    "\n",
    "# Load images from the path with different focus\n",
    "\n",
    "valid_images = [\".jpg\",\".png\",\".gif\"]\n",
    "for f in listdir_nohidden(path):\n",
    "    \n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    else :\n",
    "        if ext.lower()==\".gif\":\n",
    "            ## Read the gif from disk to `RGB`s using `imageio.miread` \n",
    "\n",
    "            gif=Image.open((os.path.join(path,f)))\n",
    "            imgs.append(np.array(gif.convert('RGB')))\n",
    "        else:\n",
    "            imgs.append(cv2.imread(os.path.join(path,f)))\n",
    "\n",
    "images = tuple(imgs)\n",
    "# Plot them\n",
    "for i in range(len(images)):\n",
    "    cv2.imshow(\"image \" + str(i+1) , images[i])\n",
    "    cv2.waitKey(0); cv2.destroyAllWindows(); cv2.waitKey(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################### A : Two scales image decomposition ###########################################################\n",
    "#images_gray=tuple([cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in images])\n",
    "#images=tuple([img.astype(float) for img in images])\n",
    "#images_gray=tuple([img.astype(float) for img in images_gray])\n",
    "\n",
    "# Size of averaging kernel for basis/details decomposition\n",
    "avg_size = 31\n",
    "# Get basis and details images\n",
    "bases_tuple, details_tuple = basis_details_decomposition(images, avg_size)\n",
    "# See result of basis/details decomposition\n",
    "for i in range(len(images)):\n",
    "    cv2.imshow('Base Layer B' + str(i+1) , cv2.convertScaleAbs(bases_tuple[i]))\n",
    "    cv2.waitKey(0); cv2.destroyAllWindows(); cv2.waitKey(1)\n",
    "    cv2.imshow('Details Layer B' + str(i+1) , cv2.convertScaleAbs(details_tuple[i]))\n",
    "    cv2.waitKey(0); cv2.destroyAllWindows(); cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################### B : Weight map construction with guided filtering ############################################\n",
    "\n",
    "# Laplacian filter size\n",
    "lapsize = 1\n",
    "# Parameters for Gaussian lowpass filter\n",
    "rg = 5\n",
    "sigmag = 5\n",
    "# Compute laplacians\n",
    "saliency_tuple = saliency_maps(images, lapsize, rg, sigmag)\n",
    "for i in range(len(images)):\n",
    "    cv2.imshow(\"saliency\"+ str(i+1), saliency_tuple[i])\n",
    "    cv2.waitKey(0); cv2.destroyAllWindows(); cv2.waitKey(1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weight maps\n",
    "weight_maps = weight_map_construction(saliency_tuple)\n",
    "# Vizualize weight map, we multiply by 255 to distinguish the pixel equal to 1 from those equal to 0\n",
    "for i in range(len(images)):\n",
    "    cv2.imshow(\"weight maps \"+ str(i+1), weight_maps[i]*255)\n",
    "    cv2.waitKey(0); cv2.destroyAllWindows(); cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refined weight maps using guided filtering\n",
    "eps1 = 0.1\n",
    "r1 = 7\n",
    "refined_wm_basis = refined_weight_maps(weight_maps, images, r1, eps1)\n",
    "eps2 = 0.225 #1\n",
    "r2 =7\n",
    "refined_wm_details = refined_weight_maps(weight_maps, images, r2, eps2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of weight maps\n",
    "refined_normalized_bases = weight_maps_normalization(refined_wm_basis)\n",
    "refined_normalized_details = weight_maps_normalization(refined_wm_details)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fused basis and fused details\n",
    "fused_bases = images_weighted_average(refined_normalized_bases, bases_tuple)\n",
    "fused_details = images_weighted_average(refined_normalized_details, details_tuple)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fused image\n",
    "fused_image = fused_bases + fused_details\n",
    "fused_image_uint8 = cv2.convertScaleAbs(fused_image)\n",
    "cv2.imshow(\"Fused image\", fused_image_uint8)\n",
    "cv2.waitKey(0); cv2.destroyAllWindows(); cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
